{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_hub as hub\n",
    "from data import galsim\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'pixel-cnn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.7/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "data_dir='/usr/local/share/galsim/COSMOS_25.2_training_sample'\n",
    "batch_size=32\n",
    "\n",
    "# Let's build an input function for the model\n",
    "input_fn = galsim.build_input_pipeline(data_dir,\n",
    "                                        batch_size=batch_size,\n",
    "                                        stamp_size=32,\n",
    "                                        pixel_size=0.06,\n",
    "                                        input_nprocs=12,\n",
    "                                        nrepeat=10,\n",
    "                                        cache_dir='/data2/COSMOS/cache32_10_hst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pixelCNN Estimator\n",
    "from pixel_cnn_pp.model import model_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_images(images, rows, cols):\n",
    "    \"\"\"Helper utility to make a field of images.\"\"\"\n",
    "    shape = tf.shape(images)\n",
    "    width = shape[-3]\n",
    "    height = shape[-2]\n",
    "    depth = shape[-1]\n",
    "    images = tf.reshape(images, (-1, width, height, depth))\n",
    "    batch = tf.shape(images)[0]\n",
    "    rows = tf.minimum(rows, batch)\n",
    "    cols = tf.minimum(batch // rows, cols)\n",
    "    images = images[:rows * cols]\n",
    "    images = tf.reshape(images, (rows, cols, width, height, depth))\n",
    "    images = tf.transpose(images, [0, 2, 1, 3, 4])\n",
    "    images = tf.reshape(images, [1, rows * width, cols * height, depth])\n",
    "    return images\n",
    "\n",
    "\n",
    "def image_tile_summary(name, tensor, rows=8, cols=8):\n",
    "    tf.summary.image(name, pack_images(tensor, rows, cols), max_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels=1\n",
    "image_size=32\n",
    "\n",
    "def pixelcnn_model_fn(features, labels, mode, params, config):\n",
    "    is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Extract input images\n",
    "    x = features['x']\n",
    "    \n",
    "    model_opt = { 'nr_resnet': 2, 'nr_filters': 64, 'nr_logistic_mix': 1, 'resnet_nonlinearity': 'concat_elu', 'energy_distance': False}\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        # Build the model\n",
    "        def make_model_spec():\n",
    "            input_layer = tf.placeholder(tf.float32, shape=[1,image_size, image_size,1])\n",
    "            model = tf.make_template('model', model_spec)\n",
    "            out = model(input_layer, None, ema=None, dropout_p=0., **model_opt)\n",
    "            out = tf.layers.dense(out, 2, activation=None) # project the output to only 2 values\n",
    "            loc, scale = tf.split(out, num_or_size_splits=2,axis=-1)\n",
    "            scale = tf.nn.softplus(scale) + 1e-4\n",
    "            distribution = tfp.distributions.Independent( tfp.distributions.Normal(loc=loc, scale=scale))\n",
    "            log_prob = - distribution.log_prob(input_layer)\n",
    "            print(log_prob)\n",
    "            grads = tf.gradients(log_prob[0], input_layer)\n",
    "            samples = distribution.sample()\n",
    "            hub.add_signature(inputs=input_layer,\n",
    "                              outputs={'grads':grads[0], 'sample':samples,'log_prob':log_prob})\n",
    "        \n",
    "        spec = hub.create_module_spec(make_model_spec, drop_collections=['checkpoints'])\n",
    "        pixelcnn = hub.Module(spec, name=\"pixelcnn_module\")\n",
    "            \n",
    "        hub.register_module_for_export(pixelcnn, \"pixelcnn_out\")\n",
    "        predictions =  pixelcnn(x, as_dict=True)\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          predictions=predictions)\n",
    "    \n",
    "    # Build the model\n",
    "    def make_model_spec():\n",
    "        input_layer = tf.placeholder(tf.float32, shape=[batch_size, image_size, image_size, n_channels])\n",
    "        \n",
    "        model = tf.make_template('model', model_spec)\n",
    "        out = model(input_layer, None, ema=None, dropout_p=0.5, **model_opt)\n",
    "        out = tf.layers.dense(out, 2, activation=None) # project the output to only 2 values\n",
    "        loc, scale = tf.split(out, num_or_size_splits=2,axis=-1)\n",
    "        scale = tf.nn.softplus(scale) + 1e-4\n",
    "        print(loc, scale)\n",
    "        # Build Gaussian model for output value\n",
    "        distribution = tfp.distributions.Independent( tfp.distributions.Normal(loc=loc, scale=scale))\n",
    "        sample = distribution.sample()\n",
    "        log_prob = distribution.log_prob(input_layer)\n",
    "        hub.add_signature(inputs=input_layer,\n",
    "                          outputs={'sample': sample, 'log_prob': log_prob})\n",
    "\n",
    "    spec = hub.create_module_spec(make_model_spec, drop_collections=['checkpoints'])\n",
    "    pixelcnn = hub.Module(spec, name=\"pixelcnn_module\", trainable=True)\n",
    "\n",
    "    output = pixelcnn(x, as_dict=True)\n",
    "\n",
    "    loglikelihood = output['log_prob']\n",
    "    sample = output['sample']\n",
    "    print(loglikelihood)\n",
    "    print(sample)\n",
    "    tf.summary.scalar('loglikelihood', tf.reduce_mean(loglikelihood))\n",
    "\n",
    "    image_tile_summary(\"image\", tf.to_float(x[:16]), rows=4, cols=4)\n",
    "    image_tile_summary(\"recon\", tf.to_float(sample[:16]), rows=4, cols=4)\n",
    "\n",
    "    loss = -tf.reduce_mean(loglikelihood)\n",
    "\n",
    "    # Training of the model\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    learning_rate = tf.train.cosine_decay(params[\"learning_rate\"], global_step,\n",
    "                                          params[\"max_steps\"])\n",
    "    tf.summary.scalar(\"learning_rate\", learning_rate)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "        train_op = optimizer.minimize(loss , global_step=global_step)\n",
    "\n",
    "    eval_metric_ops = {\"loglikelihood\": tf.metrics.mean(tf.reduce_mean(loglikelihood))}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      loss=loss,\n",
    "                                      train_op=train_op,\n",
    "                                      eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'learning_rate':0.00002, 'max_steps':400000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/data2/cosmos_pixel_cnn_hst_32', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f38611f37f0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "mymodel = tf.estimator.Estimator(model_fn=pixelcnn_model_fn,\n",
    "                                params=params, model_dir='/data2/cosmos_pixel_cnn_hst_32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/lib/python3.7/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"split:0\", shape=(32, 32, 32, 1), dtype=float32) Tensor(\"add:0\", shape=(32, 32, 32, 1), dtype=float32)\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "Tensor(\"pixelcnn_module_apply_default/IndependentNormal/log_prob/Sum:0\", shape=(32,), dtype=float32)\n",
      "Tensor(\"pixelcnn_module_apply_default/IndependentNormal/sample/Reshape:0\", shape=(32, 32, 32, 1), dtype=float32)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data2/cosmos_pixel_cnn_hst_32/model.ckpt-100000\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 100000 into /data2/cosmos_pixel_cnn_hst_32/model.ckpt.\n",
      "INFO:tensorflow:loss = -2952.3147, step = 100000\n",
      "INFO:tensorflow:global_step/sec: 6.94947\n",
      "INFO:tensorflow:loss = -2993.8638, step = 100100 (14.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.13029\n",
      "INFO:tensorflow:loss = -2988.044, step = 100200 (10.953 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.08389\n",
      "INFO:tensorflow:loss = -2850.4526, step = 100300 (11.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.04721\n",
      "INFO:tensorflow:loss = -2920.4038, step = 100400 (11.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.03412\n",
      "INFO:tensorflow:loss = -2967.96, step = 100500 (11.070 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.96116\n",
      "INFO:tensorflow:loss = -2953.8706, step = 100600 (11.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.99357\n",
      "INFO:tensorflow:loss = -2793.8225, step = 100700 (11.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.02104\n",
      "INFO:tensorflow:loss = -2992.8071, step = 100800 (11.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.00315\n",
      "INFO:tensorflow:loss = -3017.718, step = 100900 (11.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.99267\n",
      "INFO:tensorflow:loss = -2936.5532, step = 101000 (11.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.00903\n",
      "INFO:tensorflow:loss = -2862.2388, step = 101100 (11.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.01364\n",
      "INFO:tensorflow:loss = -2894.5476, step = 101200 (11.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.93561\n",
      "INFO:tensorflow:loss = -3002.3657, step = 101300 (11.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.97346\n",
      "INFO:tensorflow:loss = -2821.9805, step = 101400 (11.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90867\n",
      "INFO:tensorflow:loss = -2892.2922, step = 101500 (11.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.88493\n",
      "INFO:tensorflow:loss = -2972.258, step = 101600 (11.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.92197\n",
      "INFO:tensorflow:loss = -2841.2954, step = 101700 (11.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87885\n",
      "INFO:tensorflow:loss = -2959.0256, step = 101800 (11.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89986\n",
      "INFO:tensorflow:loss = -2753.1223, step = 101900 (11.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.91798\n",
      "INFO:tensorflow:loss = -2964.5925, step = 102000 (11.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.91207\n",
      "INFO:tensorflow:loss = -2846.6604, step = 102100 (11.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89441\n",
      "INFO:tensorflow:loss = -2923.5396, step = 102200 (11.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85823\n",
      "INFO:tensorflow:loss = -2896.9954, step = 102300 (11.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90523\n",
      "INFO:tensorflow:loss = -2920.6775, step = 102400 (11.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87882\n",
      "INFO:tensorflow:loss = -2971.1956, step = 102500 (11.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7862\n",
      "INFO:tensorflow:loss = -2859.9866, step = 102600 (11.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85426\n",
      "INFO:tensorflow:loss = -2990.5037, step = 102700 (11.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81999\n",
      "INFO:tensorflow:loss = -2818.6094, step = 102800 (11.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81626\n",
      "INFO:tensorflow:loss = -2970.6553, step = 102900 (11.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85093\n",
      "INFO:tensorflow:loss = -2957.8123, step = 103000 (11.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89646\n",
      "INFO:tensorflow:loss = -2967.1802, step = 103100 (11.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89676\n",
      "INFO:tensorflow:loss = -2879.2153, step = 103200 (11.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.65135\n",
      "INFO:tensorflow:loss = -2940.4907, step = 103300 (11.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84326\n",
      "INFO:tensorflow:loss = -2878.1045, step = 103400 (11.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.70916\n",
      "INFO:tensorflow:loss = -2923.661, step = 103500 (11.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84933\n",
      "INFO:tensorflow:loss = -2989.2554, step = 103600 (11.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76635\n",
      "INFO:tensorflow:loss = -2930.21, step = 103700 (11.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82688\n",
      "INFO:tensorflow:loss = -2944.9612, step = 103800 (11.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82265\n",
      "INFO:tensorflow:loss = -2977.7124, step = 103900 (11.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75128\n",
      "INFO:tensorflow:loss = -2880.2656, step = 104000 (11.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86239\n",
      "INFO:tensorflow:loss = -2944.0903, step = 104100 (11.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82889\n",
      "INFO:tensorflow:loss = -2900.1504, step = 104200 (11.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76455\n",
      "INFO:tensorflow:loss = -2932.9312, step = 104300 (11.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90133\n",
      "INFO:tensorflow:loss = -2911.0093, step = 104400 (11.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86642\n",
      "INFO:tensorflow:loss = -2923.5586, step = 104500 (11.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.74066\n",
      "INFO:tensorflow:loss = -2925.4946, step = 104600 (11.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76363\n",
      "INFO:tensorflow:loss = -2952.2297, step = 104700 (11.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77655\n",
      "INFO:tensorflow:loss = -2952.2341, step = 104800 (11.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83555\n",
      "INFO:tensorflow:loss = -2920.3757, step = 104900 (11.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.88306\n",
      "INFO:tensorflow:loss = -2857.709, step = 105000 (11.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7733\n",
      "INFO:tensorflow:loss = -2871.2656, step = 105100 (11.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81338\n",
      "INFO:tensorflow:loss = -2842.0156, step = 105200 (11.347 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 105265 into /data2/cosmos_pixel_cnn_hst_32/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.02913\n",
      "INFO:tensorflow:loss = -2978.6475, step = 105300 (12.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80957\n",
      "INFO:tensorflow:loss = -2923.749, step = 105400 (11.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78248\n",
      "INFO:tensorflow:loss = -2939.3896, step = 105500 (11.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8089\n",
      "INFO:tensorflow:loss = -2939.351, step = 105600 (11.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80848\n",
      "INFO:tensorflow:loss = -2959.187, step = 105700 (11.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83699\n",
      "INFO:tensorflow:loss = -2976.6177, step = 105800 (11.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76401\n",
      "INFO:tensorflow:loss = -2939.895, step = 105900 (11.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89437\n",
      "INFO:tensorflow:loss = -3019.7046, step = 106000 (11.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86494\n",
      "INFO:tensorflow:loss = -2892.5737, step = 106100 (11.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85535\n",
      "INFO:tensorflow:loss = -2871.5657, step = 106200 (11.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85263\n",
      "INFO:tensorflow:loss = -2849.3076, step = 106300 (11.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73272\n",
      "INFO:tensorflow:loss = -2992.2397, step = 106400 (11.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71489\n",
      "INFO:tensorflow:loss = -2929.4126, step = 106500 (11.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82233\n",
      "INFO:tensorflow:loss = -2887.8318, step = 106600 (11.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8722\n",
      "INFO:tensorflow:loss = -2925.0422, step = 106700 (11.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82241\n",
      "INFO:tensorflow:loss = -2972.2327, step = 106800 (11.335 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.87511\n",
      "INFO:tensorflow:loss = -2917.692, step = 106900 (11.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8144\n",
      "INFO:tensorflow:loss = -2883.2383, step = 107000 (11.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81611\n",
      "INFO:tensorflow:loss = -2902.9187, step = 107100 (11.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81274\n",
      "INFO:tensorflow:loss = -2846.146, step = 107200 (11.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.70064\n",
      "INFO:tensorflow:loss = -2949.6677, step = 107300 (11.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82283\n",
      "INFO:tensorflow:loss = -2950.0386, step = 107400 (11.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84875\n",
      "INFO:tensorflow:loss = -2903.45, step = 107500 (11.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73321\n",
      "INFO:tensorflow:loss = -2846.0085, step = 107600 (11.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7566\n",
      "INFO:tensorflow:loss = -2993.6174, step = 107700 (11.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80948\n",
      "INFO:tensorflow:loss = -2999.5742, step = 107800 (11.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79501\n",
      "INFO:tensorflow:loss = -3004.3599, step = 107900 (11.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80633\n",
      "INFO:tensorflow:loss = -2914.9937, step = 108000 (11.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81344\n",
      "INFO:tensorflow:loss = -2916.5854, step = 108100 (11.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73763\n",
      "INFO:tensorflow:loss = -2785.4314, step = 108200 (11.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82628\n",
      "INFO:tensorflow:loss = -2919.1846, step = 108300 (11.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79345\n",
      "INFO:tensorflow:loss = -2977.0151, step = 108400 (11.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80733\n",
      "INFO:tensorflow:loss = -2948.7998, step = 108500 (11.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8398\n",
      "INFO:tensorflow:loss = -2806.809, step = 108600 (11.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75208\n",
      "INFO:tensorflow:loss = -2874.5034, step = 108700 (11.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83071\n",
      "INFO:tensorflow:loss = -2987.2534, step = 108800 (11.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80285\n",
      "INFO:tensorflow:loss = -2990.8276, step = 108900 (11.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86882\n",
      "INFO:tensorflow:loss = -2863.5913, step = 109000 (11.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78285\n",
      "INFO:tensorflow:loss = -2836.889, step = 109100 (11.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82849\n",
      "INFO:tensorflow:loss = -2843.7185, step = 109200 (11.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76841\n",
      "INFO:tensorflow:loss = -2846.9006, step = 109300 (11.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81589\n",
      "INFO:tensorflow:loss = -3017.1443, step = 109400 (11.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81588\n",
      "INFO:tensorflow:loss = -2963.5664, step = 109500 (11.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78316\n",
      "INFO:tensorflow:loss = -2899.4314, step = 109600 (11.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84986\n",
      "INFO:tensorflow:loss = -2886.3726, step = 109700 (11.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71345\n",
      "INFO:tensorflow:loss = -2907.3608, step = 109800 (11.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80282\n",
      "INFO:tensorflow:loss = -2907.4224, step = 109900 (11.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.89178\n",
      "INFO:tensorflow:loss = -2893.7612, step = 110000 (11.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8731\n",
      "INFO:tensorflow:loss = -2856.0964, step = 110100 (11.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71544\n",
      "INFO:tensorflow:loss = -2935.92, step = 110200 (11.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83219\n",
      "INFO:tensorflow:loss = -2872.7798, step = 110300 (11.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72297\n",
      "INFO:tensorflow:loss = -2882.599, step = 110400 (11.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76124\n",
      "INFO:tensorflow:loss = -2935.4053, step = 110500 (11.414 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 110539 into /data2/cosmos_pixel_cnn_hst_32/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.0554\n",
      "INFO:tensorflow:loss = -2873.5098, step = 110600 (12.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86243\n",
      "INFO:tensorflow:loss = -2913.2046, step = 110700 (11.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84845\n",
      "INFO:tensorflow:loss = -2894.7712, step = 110800 (11.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80936\n",
      "INFO:tensorflow:loss = -2875.9695, step = 110900 (11.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86745\n",
      "INFO:tensorflow:loss = -2907.594, step = 111000 (11.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77042\n",
      "INFO:tensorflow:loss = -2947.31, step = 111100 (11.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83554\n",
      "INFO:tensorflow:loss = -2827.116, step = 111200 (11.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.88215\n",
      "INFO:tensorflow:loss = -2933.3252, step = 111300 (11.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73578\n",
      "INFO:tensorflow:loss = -2903.56, step = 111400 (11.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76861\n",
      "INFO:tensorflow:loss = -2950.6338, step = 111500 (11.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8287\n",
      "INFO:tensorflow:loss = -2978.656, step = 111600 (11.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82428\n",
      "INFO:tensorflow:loss = -2834.774, step = 111700 (11.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.797\n",
      "INFO:tensorflow:loss = -2981.3828, step = 111800 (11.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80988\n",
      "INFO:tensorflow:loss = -2877.4229, step = 111900 (11.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82873\n",
      "INFO:tensorflow:loss = -2859.3533, step = 112000 (11.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87952\n",
      "INFO:tensorflow:loss = -2953.9507, step = 112100 (11.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.6951\n",
      "INFO:tensorflow:loss = -2999.9768, step = 112200 (11.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75609\n",
      "INFO:tensorflow:loss = -2980.7002, step = 112300 (11.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82749\n",
      "INFO:tensorflow:loss = -2857.6777, step = 112400 (11.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76911\n",
      "INFO:tensorflow:loss = -2836.1074, step = 112500 (11.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81149\n",
      "INFO:tensorflow:loss = -2968.8826, step = 112600 (11.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8036\n",
      "INFO:tensorflow:loss = -2842.5752, step = 112700 (11.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80719\n",
      "INFO:tensorflow:loss = -2949.0117, step = 112800 (11.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.88497\n",
      "INFO:tensorflow:loss = -2950.9778, step = 112900 (11.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83815\n",
      "INFO:tensorflow:loss = -2865.9707, step = 113000 (11.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7589\n",
      "INFO:tensorflow:loss = -2891.6772, step = 113100 (11.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84474\n",
      "INFO:tensorflow:loss = -2927.3838, step = 113200 (11.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8744\n",
      "INFO:tensorflow:loss = -2914.62, step = 113300 (11.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7605\n",
      "INFO:tensorflow:loss = -2985.9932, step = 113400 (11.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71006\n",
      "INFO:tensorflow:loss = -2920.1172, step = 113500 (11.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8621\n",
      "INFO:tensorflow:loss = -2883.4688, step = 113600 (11.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84801\n",
      "INFO:tensorflow:loss = -2925.0437, step = 113700 (11.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.84104\n",
      "INFO:tensorflow:loss = -3002.016, step = 113800 (11.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76017\n",
      "INFO:tensorflow:loss = -2918.475, step = 113900 (11.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7921\n",
      "INFO:tensorflow:loss = -2838.0874, step = 114000 (11.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79929\n",
      "INFO:tensorflow:loss = -2873.185, step = 114100 (11.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76998\n",
      "INFO:tensorflow:loss = -2920.1226, step = 114200 (11.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8342\n",
      "INFO:tensorflow:loss = -3020.7966, step = 114300 (11.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.69307\n",
      "INFO:tensorflow:loss = -2885.4858, step = 114400 (11.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77768\n",
      "INFO:tensorflow:loss = -2940.2654, step = 114500 (11.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72953\n",
      "INFO:tensorflow:loss = -2965.932, step = 114600 (11.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73605\n",
      "INFO:tensorflow:loss = -2839.4492, step = 114700 (11.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = -2949.1338, step = 114800 (11.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79671\n",
      "INFO:tensorflow:loss = -2789.5703, step = 114900 (11.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80991\n",
      "INFO:tensorflow:loss = -2895.9424, step = 115000 (11.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.67287\n",
      "INFO:tensorflow:loss = -2933.5764, step = 115100 (11.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.74927\n",
      "INFO:tensorflow:loss = -2897.2878, step = 115200 (11.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76039\n",
      "INFO:tensorflow:loss = -2931.0652, step = 115300 (11.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.6612\n",
      "INFO:tensorflow:loss = -2961.728, step = 115400 (11.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82776\n",
      "INFO:tensorflow:loss = -2860.5784, step = 115500 (11.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81093\n",
      "INFO:tensorflow:loss = -2831.7654, step = 115600 (11.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75773\n",
      "INFO:tensorflow:loss = -2925.2383, step = 115700 (11.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82658\n",
      "INFO:tensorflow:loss = -3006.1162, step = 115800 (11.330 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 115807 into /data2/cosmos_pixel_cnn_hst_32/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 8.05298\n",
      "INFO:tensorflow:loss = -2838.5154, step = 115900 (12.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78453\n",
      "INFO:tensorflow:loss = -2980.7852, step = 116000 (11.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72966\n",
      "INFO:tensorflow:loss = -2923.1392, step = 116100 (11.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81735\n",
      "INFO:tensorflow:loss = -2908.6367, step = 116200 (11.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7164\n",
      "INFO:tensorflow:loss = -2973.1758, step = 116300 (11.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75468\n",
      "INFO:tensorflow:loss = -2817.669, step = 116400 (11.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.68998\n",
      "INFO:tensorflow:loss = -2954.5845, step = 116500 (11.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87929\n",
      "INFO:tensorflow:loss = -2791.518, step = 116600 (11.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81442\n",
      "INFO:tensorflow:loss = -2870.8628, step = 116700 (11.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77853\n",
      "INFO:tensorflow:loss = -2873.7717, step = 116800 (11.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73338\n",
      "INFO:tensorflow:loss = -2873.253, step = 116900 (11.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.74766\n",
      "INFO:tensorflow:loss = -2998.4688, step = 117000 (11.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77515\n",
      "INFO:tensorflow:loss = -2988.9468, step = 117100 (11.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77954\n",
      "INFO:tensorflow:loss = -2899.1904, step = 117200 (11.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78609\n",
      "INFO:tensorflow:loss = -2851.3433, step = 117300 (11.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77444\n",
      "INFO:tensorflow:loss = -2856.4224, step = 117400 (11.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7692\n",
      "INFO:tensorflow:loss = -3037.6416, step = 117500 (11.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76808\n",
      "INFO:tensorflow:loss = -2920.4746, step = 117600 (11.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.90552\n",
      "INFO:tensorflow:loss = -2892.3162, step = 117700 (11.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71384\n",
      "INFO:tensorflow:loss = -2905.6987, step = 117800 (11.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76602\n",
      "INFO:tensorflow:loss = -2978.803, step = 117900 (11.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76975\n",
      "INFO:tensorflow:loss = -2860.2969, step = 118000 (11.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82244\n",
      "INFO:tensorflow:loss = -2903.5532, step = 118100 (11.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.87046\n",
      "INFO:tensorflow:loss = -2974.106, step = 118200 (11.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7658\n",
      "INFO:tensorflow:loss = -2983.4736, step = 118300 (11.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.74851\n",
      "INFO:tensorflow:loss = -2890.189, step = 118400 (11.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83913\n",
      "INFO:tensorflow:loss = -2921.8794, step = 118500 (11.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75569\n",
      "INFO:tensorflow:loss = -2891.934, step = 118600 (11.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77482\n",
      "INFO:tensorflow:loss = -2900.7605, step = 118700 (11.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83711\n",
      "INFO:tensorflow:loss = -2831.321, step = 118800 (11.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82271\n",
      "INFO:tensorflow:loss = -2900.8042, step = 118900 (11.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81932\n",
      "INFO:tensorflow:loss = -2885.2427, step = 119000 (11.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.74918\n",
      "INFO:tensorflow:loss = -2921.9656, step = 119100 (11.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.86163\n",
      "INFO:tensorflow:loss = -2950.9338, step = 119200 (11.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78513\n",
      "INFO:tensorflow:loss = -2914.6973, step = 119300 (11.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76512\n",
      "INFO:tensorflow:loss = -3022.563, step = 119400 (11.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7679\n",
      "INFO:tensorflow:loss = -2974.9177, step = 119500 (11.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81017\n",
      "INFO:tensorflow:loss = -2920.834, step = 119600 (11.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85042\n",
      "INFO:tensorflow:loss = -2919.105, step = 119700 (11.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77883\n",
      "INFO:tensorflow:loss = -2891.6782, step = 119800 (11.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81942\n",
      "INFO:tensorflow:loss = -2872.8735, step = 119900 (11.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72764\n",
      "INFO:tensorflow:loss = -2940.205, step = 120000 (11.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72821\n",
      "INFO:tensorflow:loss = -2980.955, step = 120100 (11.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75417\n",
      "INFO:tensorflow:loss = -2886.3125, step = 120200 (11.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.7687\n",
      "INFO:tensorflow:loss = -2848.2183, step = 120300 (11.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83587\n",
      "INFO:tensorflow:loss = -2852.458, step = 120400 (11.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75466\n",
      "INFO:tensorflow:loss = -2894.297, step = 120500 (11.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82107\n",
      "INFO:tensorflow:loss = -2858.7195, step = 120600 (11.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79874\n",
      "INFO:tensorflow:loss = -2808.309, step = 120700 (11.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82855\n",
      "INFO:tensorflow:loss = -2968.7827, step = 120800 (11.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73461\n",
      "INFO:tensorflow:loss = -2878.0835, step = 120900 (11.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.72696\n",
      "INFO:tensorflow:loss = -2849.1777, step = 121000 (11.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 121068 into /data2/cosmos_pixel_cnn_hst_32/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.99056\n",
      "INFO:tensorflow:loss = -2918.1006, step = 121100 (12.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75595\n",
      "INFO:tensorflow:loss = -2871.7256, step = 121200 (11.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79738\n",
      "INFO:tensorflow:loss = -2990.3716, step = 121300 (11.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77302\n",
      "INFO:tensorflow:loss = -2904.5564, step = 121400 (11.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83951\n",
      "INFO:tensorflow:loss = -2888.3628, step = 121500 (11.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77723\n",
      "INFO:tensorflow:loss = -2878.244, step = 121600 (11.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.75081\n",
      "INFO:tensorflow:loss = -2931.606, step = 121700 (11.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.82821\n",
      "INFO:tensorflow:loss = -2896.7754, step = 121800 (11.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80996\n",
      "INFO:tensorflow:loss = -2908.9639, step = 121900 (11.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.71844\n",
      "INFO:tensorflow:loss = -3010.449, step = 122000 (11.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.62863\n",
      "INFO:tensorflow:loss = -2949.2676, step = 122100 (11.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80733\n",
      "INFO:tensorflow:loss = -2928.1885, step = 122200 (11.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76932\n",
      "INFO:tensorflow:loss = -2970.3123, step = 122300 (11.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8527\n",
      "INFO:tensorflow:loss = -2855.2622, step = 122400 (11.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83355\n",
      "INFO:tensorflow:loss = -2991.745, step = 122500 (11.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.844\n",
      "INFO:tensorflow:loss = -2830.6567, step = 122600 (11.307 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.75213\n",
      "INFO:tensorflow:loss = -2920.0713, step = 122700 (11.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83451\n",
      "INFO:tensorflow:loss = -2921.1335, step = 122800 (11.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81779\n",
      "INFO:tensorflow:loss = -3008.452, step = 122900 (11.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83656\n",
      "INFO:tensorflow:loss = -2958.9573, step = 123000 (11.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83053\n",
      "INFO:tensorflow:loss = -2886.506, step = 123100 (11.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79602\n",
      "INFO:tensorflow:loss = -2952.5994, step = 123200 (11.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.73531\n",
      "INFO:tensorflow:loss = -2885.6611, step = 123300 (11.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.76182\n",
      "INFO:tensorflow:loss = -2766.6943, step = 123400 (11.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.80058\n",
      "INFO:tensorflow:loss = -2980.4702, step = 123500 (11.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.83397\n",
      "INFO:tensorflow:loss = -2995.0676, step = 123600 (11.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79122\n",
      "INFO:tensorflow:loss = -2953.5122, step = 123700 (11.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.85677\n",
      "INFO:tensorflow:loss = -2965.0767, step = 123800 (11.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.70773\n",
      "INFO:tensorflow:loss = -2911.0474, step = 123900 (11.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.78755\n",
      "INFO:tensorflow:loss = -2910.3252, step = 124000 (11.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.88239\n",
      "INFO:tensorflow:loss = -2897.4233, step = 124100 (11.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.81537\n",
      "INFO:tensorflow:loss = -2921.2998, step = 124200 (11.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.8209\n",
      "INFO:tensorflow:loss = -2893.1445, step = 124300 (11.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.69284\n",
      "INFO:tensorflow:loss = -2937.8535, step = 124400 (11.504 sec)\n"
     ]
    }
   ],
   "source": [
    "mymodel.train(input_fn, steps=400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n",
      "/usr/lib/python3.7/site-packages/numpy/lib/type_check.py:546: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  'a.item() instead', DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Neg:0\", shape=(1,), dtype=float32)\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Restoring parameters from /data2/cosmos_pixel_cnn_hst_32/model.ckpt-500000\n",
      "INFO:tensorflow:Exported TF-Hub module to: b\"/data2/cosmos_pixel_cnn_hst/temp-b'1553635621'/pixelcnn_out\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'/data2/cosmos_pixel_cnn_hst/1553635621'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to export the trained model:\n",
    "exporter = hub.LatestModuleExporter(\"tf_hub\",\n",
    "        tf.estimator.export.build_raw_serving_input_receiver_fn(input_fn()[0]))\n",
    "\n",
    "exporter.export(mymodel, '/data2/cosmos_pixel_cnn_hst/', mymodel.latest_checkpoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelcnn_model = hub.Module('/data2/cosmos_pixel_cnn_hst/1553635621/pixelcnn_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(shape=(1,32,32,1), dtype=tf.float32)\n",
    "d = pixelcnn_model(x,as_dict=True)\n",
    "out = d['sample']\n",
    "g = d['grads']\n",
    "l = d['log_prob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = zeros((1,32,32,1))\n",
    "for i in range(32):\n",
    "    for j in range(32):\n",
    "        im[0,i,j,0] = sess.run(out, feed_dict={x: im})[0,i,j,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f3e1496d978>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(im[0,:,:,0]);colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
